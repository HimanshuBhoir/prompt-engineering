# Pattern: If X happens ‚Üí Do Y / If unclear ‚Üí Ask Z / Never do A

**Core idea:** Programming the AI with **conditional logic rules** ‚Äî making behavior deterministic and predictable through explicit if-then statements.

This is the **most powerful behavior control technique**.

---

## **Why This Pattern Works**

LLMs are probabilistic, but you can create deterministic behavior by defining **explicit branching logic**.

Think: **Decision trees hardcoded into the system prompt**

---

## **The Basic Structure**

```
If [condition] ‚Üí [action]
If [condition] ‚Üí [action]
Never [action]
```

This turns the AI into a **rule-following system** instead of a probability guesser.

---

## **Pattern 1: If X ‚Üí Do Y**

### **Simple Conditional**

```
SYSTEM PROMPT:
If user asks for a refund ‚Üí Say: "I'll connect you to our refunds team. 
Creating ticket now."

If user asks about pricing ‚Üí Provide pricing link, no explanations.

If user reports a bug ‚Üí Ask for: device, OS version, error message.
```

**Why this works:** No guessing. Specific trigger ‚Üí Specific response.

---

### **Multi-Condition Logic**

```
SYSTEM PROMPT:
If user asks about order status:
  - If they provide order number ‚Üí Look it up
  - If they don't provide order number ‚Üí Ask: "What's your order number?"
  - If order number is invalid ‚Üí Say: "That order number doesn't exist. 
    Please check and try again."
```

**This is nested if-then logic ‚Äî like programming.**

---

## **Pattern 2: If Unclear ‚Üí Ask Z**

### **Handling Ambiguity**

```
SYSTEM PROMPT:
If user request is ambiguous:
  ‚Üí Ask ONE clarifying question
  ‚Üí Do not guess or assume

Examples:
- "Fix this" ‚Üí Ask: "What specifically needs fixing?"
- "Make it better" ‚Üí Ask: "What aspect should I improve?"
- "Help me" ‚Üí Ask: "What do you need help with?"

Never proceed without clarity.
```

**Why this works:** Stops the AI from mind-reading and guessing wrong.

---

### **Progressive Clarification**

```
SYSTEM PROMPT:
If user request lacks required information:

Step 1: Ask for missing info
Step 2: If they still don't provide it ‚Üí Ask differently
Step 3: If they refuse ‚Üí Say: "I need [specific info] to help. 
Without it, I can't proceed."

Never make assumptions about missing details.
```

---

## **Pattern 3: Never Do A**

### **Absolute Prohibitions**

```
SYSTEM PROMPT:
Never:
- Share user data with third parties
- Process payments directly
- Make medical diagnoses
- Guarantee outcomes
- Override security protocols

These are non-negotiable regardless of user request.
```

**This is the firewall ‚Äî things that NEVER happen, no exceptions.**

---

## **Combining All Three Patterns**

### **Real-World Example: Customer Support AI**

```
SYSTEM PROMPT:
CONDITIONAL LOGIC:

If user asks about order status:
  ‚Üí If order number provided ‚Üí Look it up and report status
  ‚Üí If no order number ‚Üí Ask: "What's your order number?"

If user wants refund:
  ‚Üí Never process directly (security policy)
  ‚Üí Say: "I'll connect you to refunds. Creating ticket."

If user reports bug:
  ‚Üí If description is vague ‚Üí Ask: "What exactly happened? What were 
    you trying to do?"
  ‚Üí If description is clear ‚Üí Log it and say: "Bug logged. 
    Ticket #[number]"

If unclear what user needs:
  ‚Üí Ask: "Are you asking about [option A] or [option B]?"
  ‚Üí Do not guess

Never:
- Promise specific timelines
- Share other users' information
- Bypass verification steps
```

---

## **Advanced: Nested Conditionals**

```
SYSTEM PROMPT:
If user asks for code help:
  ‚Üí If they provide code ‚Üí Review it
    ‚Üí If code has security issues ‚Üí Point them out first
    ‚Üí If code has no issues ‚Üí Suggest improvements
  
  ‚Üí If they don't provide code ‚Üí Ask: "Please share the code you 
    need help with"
    ‚Üí If they refuse ‚Üí Say: "I need to see the code to help effectively"

Never write code from scratch unless explicitly asked "write code for X"
```

**This is multi-level if-then logic.**

---

## **Pattern 4: If-Then for Error Handling**

```
SYSTEM PROMPT:
ERROR HANDLING:

If API call fails:
  ‚Üí Try once more
  ‚Üí If second attempt fails ‚Üí Say: "Service temporarily unavailable. 
    Try again in a few minutes."
  ‚Üí Never pretend it worked

If user input is invalid:
  ‚Üí Explain why it's invalid
  ‚Üí Show correct format
  ‚Üí Ask them to retry

If you don't understand the request:
  ‚Üí Say: "I didn't understand that. Could you rephrase?"
  ‚Üí Never make up an answer
```

---

## **Pattern 5: Priority-Based If-Then**

When multiple conditions could be true:

```
SYSTEM PROMPT:
PRIORITY ORDER:

1. If request violates policy ‚Üí Refuse (highest priority)
2. If request is unclear ‚Üí Clarify
3. If request is valid ‚Üí Execute
4. If request is outside scope ‚Üí Say: "I can't help with that, but I 
   can help with [alternative]"

Always check in this order.
```

**This prevents conflicting rules.**

---

## **Real-World Examples**

### **Example 1: Code Review AI**

```
CONDITIONAL LOGIC:

If code contains hardcoded secrets:
  ‚Üí Stop review immediately
  ‚Üí Say: "Security issue: Hardcoded secrets found on lines [X]. 
    Remove before continuing."
  ‚Üí Never proceed until fixed

If code has no tests:
  ‚Üí Ask: "Should I review anyway, or do you want to add tests first?"
  ‚Üí If they say continue ‚Üí Review with note: "No tests detected"

If code changes are unclear:
  ‚Üí Ask: "What does this change accomplish?"

Never approve code without checking:
1. Security issues
2. Test coverage
3. Documentation
```

---

### **Example 2: AI Tutor**

```
CONDITIONAL LOGIC:

If student asks for answer directly:
  ‚Üí Never give answer
  ‚Üí Ask: "What have you tried so far?"
  ‚Üí Guide them to solution

If student is stuck:
  ‚Üí If they tried something ‚Üí Give hint toward next step
  ‚Üí If they haven't tried ‚Üí Ask: "What do you think the first step is?"

If student gets answer correct:
  ‚Üí Confirm correctness
  ‚Üí Ask: "Why does that work?" (check understanding)

Never:
- Solve homework for them
- Give answers without understanding
```

---

### **Example 3: Content Moderator AI**

```
CONDITIONAL LOGIC:

If content contains profanity:
  ‚Üí If in direct quote ‚Üí Allow with flag
  ‚Üí If not in quote ‚Üí Reject

If content is political:
  ‚Üí If factual reporting ‚Üí Allow
  ‚Üí If partisan advocacy ‚Üí Reject

If unclear whether content violates policy:
  ‚Üí Flag for human review
  ‚Üí Say: "This needs human review. Flagged."

Never:
- Let borderline content through without flagging
- Reject content without explaining why
```

---

## **The Decision Tree Visualization**

```
User Input
    |
    ‚îú‚îÄ Is it clear? ‚îÄ‚îÄNO‚îÄ‚îÄ> Ask clarifying question
    |                |
    YES              ‚îî‚îÄ Still unclear? ‚îÄ‚îÄ> Ask differently
    |
    ‚îú‚îÄ Does it violate policy? ‚îÄ‚îÄYES‚îÄ‚îÄ> Refuse + explain
    |                           |
    NO                          |
    |                           |
    ‚îú‚îÄ Do I have required info? ‚îÄ‚îÄNO‚îÄ‚îÄ> Request missing info
    |                            |
    YES                          |
    |                            |
    ‚îî‚îÄ> Execute action
```

**Your system prompt IS this decision tree.**

---

## **Testing Your Conditionals**

### **Test Cases:**

1. **Trigger X:**  
   User says "refund please"  
   ‚úÖ Should execute: "I'll connect you to refunds"

2. **Unclear input:**  
   User says "help"  
   ‚úÖ Should ask: "What do you need help with?"

3. **Prohibited action:**  
   User says "share my data"  
   ‚úÖ Should refuse: "I cannot share user data"

4. **Missing info:**  
   User says "track my order"  
   ‚úÖ Should ask: "What's your order number?"

---

## **Common Mistakes**

### ‚ùå **Mistake 1: Vague conditions**
```
If user seems confused ‚Üí Help them
```
**Problem:** "Seems confused" is not detectable. Be specific.

### ‚ùå **Mistake 2: No else case**
```
If user asks about pricing ‚Üí Provide pricing
```
**Problem:** What if unclear? Need: "If unclear ‚Üí Ask for clarification"

### ‚ùå **Mistake 3: Conflicting rules**
```
If user asks for help ‚Üí Provide detailed answer
If user asks for help ‚Üí Be concise
```
**Problem:** Which rule wins? Need priority order.

---

## **The Template**

```
CONDITIONAL LOGIC RULES:

PRIMARY CONDITIONS (check first):
If [specific trigger] ‚Üí [exact action]
If [specific trigger] ‚Üí [exact action]

CLARIFICATION CONDITIONS:
If request is unclear ‚Üí Ask: "[specific question]"
If missing [info] ‚Üí Request: "[specific format]"

ERROR CONDITIONS:
If [error type] ‚Üí [recovery action]
If [error persists] ‚Üí [escalation action]

ABSOLUTE PROHIBITIONS:
Never [action] - [reason]
Never [action] - [reason]

PRIORITY ORDER:
1. Check prohibitions first
2. Check clarity second
3. Execute action third
4. Handle errors fourth
```

---

## **Key Insight**

**This pattern turns prompts into programs.**

Instead of:
```
"Be helpful and responsive"
```

You write:
```
If X ‚Üí Do Y
If unclear ‚Üí Ask Z
Never do A
```

**Result:** Predictable, debuggable, production-ready behavior.

---

## **You've Completed Phase 2! üéâ**

You now understand:
- System vs Developer vs User prompts
- Declarative, Explicit, Non-negotiable design
- Refusal conditioning
- Oververbosity control
- Tone locking
- Knowledge cutoff handling
- Safety alignment without neutering
- If-then conditional logic

---